<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.92.2" />

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="" />
  <meta property="og:url" content="https://chamila.dev/blog/2018-11-28_publishing-wso2-logs-to-splunk-from-a-containerized-deployment/" />
  <link rel="canonical" href="https://chamila.dev/blog/2018-11-28_publishing-wso2-logs-to-splunk-from-a-containerized-deployment/" /><script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/chamila.dev\/"
      },
      "articleSection" : "blog",
      "name" : "Publishing WSO2 Logs to Splunk from a Containerized Deployment",
      "headline" : "Publishing WSO2 Logs to Splunk from a Containerized Deployment",
      "description" : "Or how to publish to Splunk from any Docker environment WSO2 products follow a standard structure when it comes to configuration, data, artifacts, and logging. Configuration files are found in \u0026lt;CARBON_HOME\u0026gt;\/repository\/conf folder, data in \u0026lt;CARBON_HOME\u0026gt;\/repository\/data, artifacts in \u0026lt;CARBON_HOME\u0026gt;\/repository\/deployment (or in \u0026lt;CARBON_HOME\u0026gt;\/repository\/tenants folder if you’re in to multi-tenancy). All the log files are written into \u0026lt;CARBON_HOME\u0026gt;\/repository\/logs folder.\nLog Aggregation All log events are output as entries to files through Log4J. Because of this, when it’s time to attach WSO2 logging to a log aggregator, it’s a matter of incorporating a tailing file reader agent and directing it towards \u0026lt;CARBON_HOME\u0026gt;\/repository\/logs folder.",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2018",
      "datePublished": "2018-11-28 09:51:30.307 \u002b0000 UTC",
      "dateModified" : "2018-11-28 09:51:30.307 \u002b0000 UTC",
      "url" : "https:\/\/chamila.dev\/blog\/2018-11-28_publishing-wso2-logs-to-splunk-from-a-containerized-deployment\/",
      "keywords" : [ "Docker","Aws Ecs","Wso2","Log Analysis","Splunk", ]
  }
</script>
<title>Publishing WSO2 Logs to Splunk from a Containerized Deployment - chamila.dev</title>
  <meta property="og:title" content="Publishing WSO2 Logs to Splunk from a Containerized Deployment - chamila.dev" />
  <meta property="og:type" content="article" />
  <meta name="description" content="Or how to publish to Splunk from any Docker environment WSO2 products follow a standard structure when it comes to configuration, data, artifacts, and logging. Configuration files are found in &lt;CARBON_HOME&gt;/repository/conf folder, data in &lt;CARBON_HOME&gt;/repository/data, artifacts in &lt;CARBON_HOME&gt;/repository/deployment (or in &lt;CARBON_HOME&gt;/repository/tenants folder if you’re in to multi-tenancy). All the log files are written into &lt;CARBON_HOME&gt;/repository/logs folder.
Log Aggregation All log events are output as entries to files through Log4J. Because of this, when it’s time to attach WSO2 logging to a log aggregator, it’s a matter of incorporating a tailing file reader agent and directing it towards &lt;CARBON_HOME&gt;/repository/logs folder." />

  <link rel="stylesheet" href="https://unpkg.com/flexboxgrid@6.3.1/dist/flexboxgrid.min.css" />
  <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/tomorrow.min.css" />
  <link rel="stylesheet" href="/css/index.css">
  <link rel="stylesheet" href="/css/light.css">
  <link rel="stylesheet" href="/css/dark.css">
  <link href="/blog/index.xml" rel="alternate" type="application/rss+xml" title="chamila.dev">

  <link href="/fa/css/all.css" rel="stylesheet">

  
  
  
  
  <script>
    

    (function (undefined) { }).call('object' === typeof window && window || 'object' === typeof self && self || 'object' === typeof global && global || {});
  </script>

  

</head>


<body class="theme-light">
  <article class="post " id="article">
    <div class="row">
      <div class="container col-xs-12 col-sm-10 col-md-8 col-sm-offset-1 col-md-offset-2 col-lg-6 col-lg-offset-3">
        <div id="floating-menu-wrapper">
  <div id="floating-menu">
    <button id="switch-to-dark" title="dark theme">
      <i class="fas fa-moon"></i>
    </button>
    <button id="switch-to-light" title="light theme" class="current-theme">
      <i class="fas fa-sun"></i>
    </button>
  </div>
</div>

        <div class="site-header">
          
<header>
  <div class="signatures site-title">
    <span class="breadcrumbs">
      <a href="https://chamila.dev/">chamila.dev</a> >
      <a href="https://chamila.dev//blog"> journal </a> >
    </span>
    <div class="sm-icons">
  <a href="https://chamila.dev//blog/index.xml" target="_blank" title="rss">
    <i class="fas fa-rss sm-icon"></i>
  </a>
  <a href="https://github.com/chamilad" target="_blank" title="github">
    <i class="fab fa-github sm-icon"></i>
  </a>
  <a href="https://fosstodon.org/@chamilad" target="_blank" title="fosstodon" rel="me">
    <i class="fab fa-mastodon sm-icon"></i>
  </a>
</div>

  </div>
</header>
<div class="row end-xs">
   
</div>


        </div>
        <header class="post-header">
          <h1 class="post-title">Publishing WSO2 Logs to Splunk from a Containerized Deployment</h1>
          
          <div class="row post-desc">
            <div class="pub-date col-xs-6">
              
              <time class="post-date" datetime=" 2018-11-28 09:51:30 UTC">
                28 Nov 2018
              </time>
              
            </div>
            <div class="reading-time col-xs-6" title="approximate read time">
              ~5 minutes
            </div>
            
            
            
          </div>
          
          <div class="toc">
            
            <h4>Table of Contents:</h4>
            <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav>
            
          </div>
        </header>
        <div class="post-content markdown-body">
          <h4 id="or-how-to-publish-to-splunk-from-any-docker-environment">Or how to publish to Splunk from any Docker environment</h4>
<p>WSO2 products follow a standard structure when it comes to configuration, data, artifacts, and logging. Configuration files are found in &lt;CARBON_HOME&gt;/repository/conf folder, data in &lt;CARBON_HOME&gt;/repository/data, artifacts in &lt;CARBON_HOME&gt;/repository/deployment (or in &lt;CARBON_HOME&gt;/repository/tenants folder if you’re in to multi-tenancy). All the log files are written into &lt;CARBON_HOME&gt;/repository/logs folder.</p>
<h4 id="log-aggregation">Log Aggregation</h4>
<p>All log events are output as entries to files through Log4J. Because of this, when it’s time to attach WSO2 logging to a log aggregator, it’s a matter of incorporating a tailing file reader agent and directing it towards &lt;CARBON_HOME&gt;/repository/logs folder. For an example, for ELK this could be something like <strong>FileBeat</strong>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#f92672">filebeat.prospectors</span>:
- <span style="color:#f92672">input_type</span>: <span style="color:#ae81ff">log</span>
  <span style="color:#f92672">paths</span>:
    - <span style="color:#ae81ff">/mnt/wso2am-2.6.0/repository/logs/*.log</span>
<span style="color:#f92672">output.logstash</span>:
  <span style="color:#f92672">hosts</span>: [<span style="color:#e6db74">&#34;logstash.private.deployment.local:5044&#34;</span>]

</code></pre></div><p>When it comes Splunk, the traditional approach for a story like this is to use the <a href="http://docs.splunk.com/Documentation/Forwarder/6.4.2/Forwarder/Abouttheuniversalforwarder">Universal Forwarder</a>. It is an agent process that will read the contents of a specified log file and push events to a specified Splunk receiver port.</p>
<p>However, this approach is not a suitable one when it comes to dynamic deployments like Docker, K8s, or ECS where instances are prone to come and go down without prior planning and notice. The gap exists when part of the Universal Forwarder configuration has to be done in the Splunk side the deployment. This will not be able to register new instances that were spawned by Container Orchestration systems both for auto healing and scaling. Furthermore, a somewhat heavy process like the Universal Forwarder running along side a JVM inside the same Container is not exactly conforming to Containerization best practices.</p>
<p>Fortunately the proper way to register log events from a Docker based deployment to Splunk is a much simpler approach.</p>
<h4 id="docker-logging">Docker Logging</h4>
<p>Docker logging design enables <a href="https://docs.docker.com/config/containers/logging/configure/">multiple logging drivers to be enabled at the Docker daemon level</a>. There are multiple logging drivers that are enabled OOTB, in addition to the ability to plugin custom logging drivers. <a href="https://docs.docker.com/config/containers/logging/configure/#supported-logging-drivers">Splunk is one of these supported logging drivers</a> that are available OOTB, where the log events will be pushed to an <a href="http://dev.splunk.com/view/event-collector/SP-CAAAE7G">HTTP Event Collector</a> endpoint at Splunk.</p>
<p>Therefore, any Docker based deployment only has to enable <code>splunk</code> as the logging driver name, and specify the required parameters in order to start publishing the events produced by the Docker Containers.</p>
<p>When it comes AWS ECS, enabling this is a bit tricky.</p>
<p>Managing the ECS Cluster Instances can be done in two ways. <code>EC2</code> is when you manage your own EC2 instances and register them in a specific ECS cluster as worker nodes. <code>FARGATE</code> is when that workload is handled by AWS Fargate.</p>
<p>The compromise in AWS Fargate is that you lose the detailed level of control you have over the Cluster Instances. At the moment, if you go for a Fargate managed ECS Cluster, you will only have <code>awslogs</code> (which publishes logs to AWS CloudWatch) and <code>none</code> as the logging options.</p>
<p>To enable OOTB logging drivers in the Docker daemon through the ECS Agent running on the Cluster Instances, you have to go with the EC2 option for managing the Cluster.</p>
<p>Now, the ECS Agent should be notified so that the Docker daemon is configured to support the list of Docker logging drivers. To do this, add the following entry to the ECS Agent configuration file and restart the ECS Agent.</p>
<pre tabindex="0"><code>ECS_AVAILABLE_LOGGING_DRIVERS=[&quot;awslogs&quot;,&quot;splunk&quot;]
</code></pre><p>As you probably have guessed by now, any number of <a href="https://docs.docker.com/config/containers/logging/configure/#supported-logging-drivers">supported Docker logging drivers </a>can be specified here.</p>
<p>When creating a Task Definition for the WSO2 deployment, in the Container definition, go down <strong>Storage and Logging</strong>section. Select the drop down list for <strong>Log Configuration</strong> to view the list of OOTB supported logging drivers.</p>
<p><img src="/blog/img/2018-11-28_publishing-wso2-logs-to-splunk-from-a-containerized-deployment_0.png#layoutTextWidth" alt=""></p>
<blockquote>
<p>While there are a list of available logging drivers, the entries in this list will not be edited depending on the values added for above mentioned ECS_AVAILABLE_LOGGING_DRIVERS agent configuration. These are only a static list of options. The existence of an option here does not necessarily mean that Docker daemon on the Cluster Instances may support them without the necessary configuration.</p>
</blockquote>
<p>Select <strong>Splunk</strong> as the <strong>Log Driver</strong> and add the following <strong>Log Options</strong>.</p>
<ul>
<li><code>splunk-url</code> — The Splunk HTTP Event Collector endpoint e.g.: <code>https://input-&lt;splunk-cloud-url&gt;:8089</code></li>
<li><code>splunk-token</code> — The access token generated at Splunk end to enable Docker to access Splunk without having to provide credentials</li>
<li><code>splunk-insecureskipverify</code> — Set to <code>true</code> if TLS verification is to be skipped for test reasons</li>
</ul>
<p>This will enable the logs created at the Docker daemon as part of the <code>stdout</code> of the running Containers to be pushed to the specified HEC endpoint at Splunk. Additional enrichment like tags could also be added as a **Log Option.**For an example, <code>tag-{{.Name}}</code> will add the name of the Container to the log event to be filtered out later. The <a href="https://docs.docker.com/config/containers/logging/log_tags/">full list of tags that can be added can be found here</a>.</p>
<h4 id="conclusion">Conclusion</h4>
<p>As this approach is tested and adopted for suitability, it may be better to create the EC2 Cluster Instances from a custom AMI that has all the ECS Agent configurations in place. That will help in managing the proper logging options in an autoscaling deployment.</p>
<p>In addition to the reduced complexity of configuring paths and registering instances when using the Universal Forwarder, this approach also conforms with the natural way of log aggregation when it comes to Docker based deployments. That will be useful to maintain a uniform log analysis strategy across deployments since log aggregation is now part of the Containerization stack rather than the application.</p>
<p>It may be possible that with future developments, AWS Fargate will also enable <code>splunk</code> as an option for <strong>Log Option</strong>entry. However for now, this is only possible with EC2 Clusters.</p>
<hr>
<p>Written on November 28, 2018 by chamila de alwis.</p>
<p>Originally published on <a href="https://medium.com/@chamilad/publishing-wso2-logs-to-splunk-from-a-containerized-deployment-a19ab743c84e">Medium</a></p>

        </div>
        <div class="prev-next row">
	<div class="prev col-sm">
	
	<a href="https://chamila.dev/blog/2018-11-25_cicd-apis-with-wso2-api-manager/">&lt; CI/CD APIs with WSO2 API Manager</a>
		
	</div>        
	<div class="next col-sm">
	
	<a href="https://chamila.dev/blog/2018-12-24_how-to-design-a-wso2-docker-image/">How to Design a WSO2 Docker Image &gt;</a>
		
	</div>
</div>


        

        

<div class="releated-content">
  <h3>Related Posts</h3>
  <ul>
    
    <li><a href="/blog/2018-11-25_cicd-apis-with-wso2-api-manager/">CI/CD APIs with WSO2 API Manager</a></li>
    
    <li><a href="/blog/2017-02-21_ballerina-with-container-support/">Ballerina with Container Support</a></li>
    
    <li><a href="/blog/2017-01-22_thinking-of-moving-your-wso2-deployment-on-to-kubernetes/">Thinking of Moving Your WSO2 Deployment On to Kubernetes?</a></li>
    
  </ul>
</div>


        
        
        
        
        

        <div class="site-footer">
  

  <div class="sm-icons">
  <a href="https://chamila.dev//blog/index.xml" target="_blank" title="rss">
    <i class="fas fa-rss sm-icon"></i>
  </a>
  <a href="https://github.com/chamilad" target="_blank" title="github">
    <i class="fab fa-github sm-icon"></i>
  </a>
  <a href="https://fosstodon.org/@chamilad" target="_blank" title="fosstodon" rel="me">
    <i class="fab fa-mastodon sm-icon"></i>
  </a>
</div>

  
  <div class="site-footer-item">
    Modified
    <a href="https://github.com/joway/hugo-theme-yinyang" target="_blank">YinYang</a>
    theme
  </div>
</div>

      </div>
    </div>
  </article>

  <script src="/js/highlight.pack.js"></script>
<script src="/js/theme.js"></script>


<script>
  hljs.initHighlightingOnLoad();

  var posts = document.getElementById('posts-list');
  posts && quicklink({
    el: posts,
    priority: true,
  });
</script>

  

</body>

</html>
